{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW (MOABB) to CSV\n",
    "\n",
    "This code convert the data sets from RAW format to CSV format using MOABB.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for BNCI2014002 (Train Runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import moabb.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Database\n",
    "m_dataset = moabb.datasets.BNCI2014_002()\n",
    "m_data = m_dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all canal names (EEG, misc, stim...)\n",
    "raws = m_data[1]['0']['0train']\n",
    "print(\"Canal list :\", raws.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Know what index is stim channel (we will need it later for the CSV to NY conversion)\n",
    "stim_channel_name = 'stim'\n",
    "stim_idx = raws.ch_names.index(stim_channel_name)\n",
    "print(f\"Canal index {stim_channel_name} is : {stim_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count stim data unique values (1 non target, 2 = target with a ratio needed of 5 to 1)\n",
    "stim_data = raws.get_data(picks=stim_idx)\n",
    "print(stim_data.shape)\n",
    "unique_vals, counts = np.unique(stim_data, return_counts=True)\n",
    "\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurences count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par exemple, pour le sujet 1 et une session donnée (ici '0' ou '1test' selon la nomenclature)\n",
    "subject = 1\n",
    "session = '0' # ou '0' selon ton cas\n",
    "\n",
    " \n",
    "# Récupérer la liste des runs dans cette session\n",
    "run_keys = sorted([key for key in m_data[subject][session].keys() if 'train' in key])\n",
    "print(\"Runs d'entraînement trouvés pour sujet 1, session 0 :\", run_keys)\n",
    "\n",
    "# Initialiser une liste pour stocker les données de chaque run\n",
    "all_runs_data = []\n",
    "\n",
    "# Parcourir chaque run d'entraînement et extraire ses données\n",
    "for run in run_keys:\n",
    "    raw_run = m_data[subject][session][run]\n",
    "    # Extraire les données : forme (n_channels, n_times_run)\n",
    "    run_data = raw_run.get_data()\n",
    "    all_runs_data.append(run_data)\n",
    "\n",
    "concatenated_data = np.concatenate(all_runs_data, axis=1)  # forme: (n_channels, total_timesamples)\n",
    "\n",
    "# Transposer pour obtenir dataT de forme (total_timesamples, n_channels)\n",
    "dataT = concatenated_data.T\n",
    "\n",
    "print(\"Forme de dataT avant suppression :\", dataT.shape)\n",
    "\n",
    "# Supprimer les 8 premiers time samples (lignes) s'ils ne contiennent que des 0\n",
    "# Pour être sûr, on peut vérifier si la somme par ligne vaut 0\n",
    "nonzero_indices = np.where(np.sum(dataT, axis=1) != 0)[0]\n",
    "dataT = dataT[nonzero_indices, :]\n",
    "\n",
    "print(\"Forme de dataT après suppression :\", dataT.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "dataT[:, -1] = np.where(dataT[:, -1] == 2, 3, dataT[:, -1])\n",
    "dataT[:, -1] = np.where(dataT[:, -1] == 1, 2, dataT[:, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire la dernière colonne (canal stim)\n",
    "stim_col = dataT[:, -1]\n",
    "\n",
    "# Compter les valeurs uniques\n",
    "unique_vals, counts = np.unique(stim_col, return_counts=True)\n",
    "\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurrence count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_times, n_channels = dataT.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df[\"\"] = df[\"\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file : subject_01_session_01.csv\n",
      "Saved file : subject_02_session_01.csv\n",
      "Saved file : subject_03_session_01.csv\n",
      "Saved file : subject_04_session_01.csv\n",
      "Saved file : subject_05_session_01.csv\n",
      "Saved file : subject_06_session_01.csv\n",
      "Saved file : subject_07_session_01.csv\n",
      "Saved file : subject_08_session_01.csv\n",
      "Saved file : subject_09_session_01.csv\n",
      "Saved file : subject_10_session_01.csv\n",
      "Saved file : subject_11_session_01.csv\n",
      "Saved file : subject_12_session_01.csv\n",
      "Saved file : subject_13_session_01.csv\n",
      "Saved file : subject_14_session_01.csv\n"
     ]
    }
   ],
   "source": [
    "subject_list = list(m_data.keys())\n",
    "\n",
    "\n",
    "for subject in subject_list:\n",
    "\n",
    "    # Récupérer la liste des runs dans cette session\n",
    "    run_keys = sorted([key for key in m_data[subject]['0'].keys() if 'test' in key])\n",
    "    \n",
    "    # Initialiser une liste pour stocker les données de chaque run\n",
    "    all_runs_data = []\n",
    "    for run in run_keys:\n",
    "        raw_run = m_data[subject]['0'][run]\n",
    "        # Extraire les données : forme (n_channels, n_times_run)\n",
    "        run_data = raw_run.get_data()\n",
    "        all_runs_data.append(run_data)\n",
    "\n",
    "    \n",
    "    # Concaténer les données le long de l'axe temporel (axis=1)\n",
    "    concatenated_data = np.concatenate(all_runs_data, axis=1)  # (n_channels, total_timesamples)\n",
    "    dataT = concatenated_data.T\n",
    "\n",
    "    nonzero_indices = np.where(np.sum(dataT, axis=1) != 0)[0]\n",
    "    dataT = dataT[nonzero_indices, :]\n",
    "\n",
    "    n_times, n_channels = dataT.shape\n",
    "    \n",
    "    dataT[:, -1] = np.where(dataT[:, -1] == 2, 3, dataT[:, -1])\n",
    "    dataT[:, -1] = np.where(dataT[:, -1] == 1, 2, dataT[:, -1])\n",
    "\n",
    "    # Création de la colonne de timestamps\n",
    "    timestamps = np.arange(n_times, dtype=int)\n",
    "    datacsv = np.column_stack((timestamps, dataT))\n",
    "    header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "    df = pd.DataFrame(datacsv, columns=header)\n",
    "    df[\"\"] = df[\"\"].astype(int)\n",
    "    \n",
    "    # Nommer le fichier\n",
    "    subject_str = f\"{int(subject):02d}\"\n",
    "    # Calculer le numéro de session à partir de la chaîne '0train' ou '1test'\n",
    "    session_str = f\"{1:02d}\"\n",
    "    filename = f\"subject_{subject_str}_session_{session_str}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved file : {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
