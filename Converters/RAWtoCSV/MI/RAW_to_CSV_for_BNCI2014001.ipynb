{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW (MOABB) to CSV\n",
    "\n",
    "This code convert the data sets from RAW format to CSV format using MOABB.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for BNCI2014001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from moabb import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Database\n",
    "m_dataset = datasets.BNCI2014001()\n",
    "m_data = m_dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all channel names (EEG, misc, stim...)\n",
    "raw = m_data[1]['0train']['0']\n",
    "print(\"Canal list :\", raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Know what index is stim channel \n",
    "stim_channel_name = 'stim'\n",
    "stim_idx = raw.ch_names.index(stim_channel_name)\n",
    "print(f\"Canal index {stim_channel_name} is : {stim_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count stim data unique values (depends on the database)\n",
    "stim_data = raw.get_data(picks=stim_idx)\n",
    "print(stim_data.shape)\n",
    "unique_vals, counts = np.unique(stim_data, return_counts=True)\n",
    "\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurences count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, for subject 1 and a given session\n",
    "# Retrieve the list of runs in this session\n",
    "run_keys = sorted(m_data[1]['0train'].keys())\n",
    "print(\"Runs found in the session:\", run_keys)\n",
    "\n",
    "# Initialize a list to store the data from each run\n",
    "all_runs_data = []\n",
    "\n",
    "# Iterate over each run and extract its data\n",
    "for run in run_keys:\n",
    "    raw_run = m_data[1]['0train'][run]\n",
    "    # Drop EOG channels (typically eye movement artifacts)\n",
    "    raw_run.drop_channels(['EOG1', 'EOG2', 'EOG3']) \n",
    "    run_data = raw_run.get_data()  # shape: (n_channels, n_times_run)\n",
    "    all_runs_data.append(run_data)\n",
    "\n",
    "# Concatenate the data along the time axis (axis=1)\n",
    "concatenated_data = np.concatenate(all_runs_data, axis=1)  # shape: (n_channels, total_timesamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose to get an array of shape (total_timesamples, n_channels)\n",
    "dataT = concatenated_data.T\n",
    "print(\"Shape of dataT:\", dataT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last column (stim channel)\n",
    "stim_col = dataT[:, -1]\n",
    "\n",
    "# Count the unique values\n",
    "unique_vals, counts = np.unique(stim_col, return_counts=True)\n",
    "\n",
    "# Loop through unique values and their counts to print the results\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurrence count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "n_times, n_channels = dataT.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df[\"\"] = df[\"\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop on all subjects\n",
    "subject_list = list(m_data.keys())\n",
    "\n",
    "# Define the sessions to process (here '0train' and '1test')\n",
    "sessions = ['0train', '1test']\n",
    "\n",
    "# Loop through all subjects\n",
    "for subject in subject_list:\n",
    "    # Loop through the defined sessions\n",
    "    for session in sessions:\n",
    "        # Retrieve the list of runs in this session\n",
    "        run_keys = sorted(m_data[subject][session].keys())\n",
    "        \n",
    "        # Initialize a list to store the data from each run\n",
    "        all_runs_data = []\n",
    "        for run in run_keys:\n",
    "            raw_run = m_data[subject][session][run]\n",
    "            # Drop EOG channels\n",
    "            raw_run.drop_channels(['EOG1', 'EOG2', 'EOG3'])\n",
    "            run_data = raw_run.get_data()  # shape: (n_channels, n_times_run)\n",
    "            all_runs_data.append(run_data)\n",
    "        \n",
    "        # Concatenate the data along the time axis (axis=1)\n",
    "        concatenated_data = np.concatenate(all_runs_data, axis=1)  # (n_channels, total_timesamples)\n",
    "        \n",
    "        # Transpose to get dataT of shape (total_timesamples, n_channels)\n",
    "        dataT = concatenated_data.T\n",
    "        n_times, n_channels = dataT.shape\n",
    "        \n",
    "        # Replace all occurrences of '4' with '6' in the last column\n",
    "        # We assume the last column corresponds to the stimulation channel.\n",
    "        dataT[:, -1] = np.where(dataT[:, -1] == 4, 6, dataT[:, -1])\n",
    "\n",
    "        # Create the timestamps column\n",
    "        timestamps = np.arange(n_times, dtype=int)\n",
    "        datacsv = np.column_stack((timestamps, dataT))\n",
    "        header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "        df = pd.DataFrame(datacsv, columns=header)\n",
    "        df[\"\"] = df[\"\"].astype(int)\n",
    "        \n",
    "        # Name the file\n",
    "        subject_str = f\"{int(subject):02d}\"\n",
    "        # Calculate the session number from the string '0train' or '1test'\n",
    "        session_str = f\"{int(session[0]) + 1:02d}\"\n",
    "        filename = f\"subject_{subject_str}_session_{session_str}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Saved file : {filename}\")\n",
    "        \n",
    "        # display info\n",
    "        events = df.iloc[:, -1]\n",
    "        n_lh = len(events[events == 1]) \n",
    "        n_rh = len(events[events == 2]) \n",
    "        n_f = len(events[events == 3]) \n",
    "        n_tongue = len(events[events == 6])\n",
    "        print(f\"Number of Left hand (1): {n_lh}\")\n",
    "        print(f\"Number of Right hand (2): {n_rh}\")\n",
    "        print(f\"Number of feet (3): {n_f}\")\n",
    "        print(f\"Number of tongue (6): {n_tongue}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
