{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW (MOABB) to CSV\n",
    "\n",
    "This code convert the data sets from RAW format to CSV format using MOABB.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for PhysionetMI-T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from moabb import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['left_hand', 'rest', 'right_hand']\n",
      "Used Annotations descriptions: ['left_hand', 'rest', 'right_hand']\n",
      "Used Annotations descriptions: ['left_hand', 'rest', 'right_hand']\n",
      "Used Annotations descriptions: ['feet', 'hands', 'rest']\n",
      "Used Annotations descriptions: ['feet', 'hands', 'rest']\n",
      "Used Annotations descriptions: ['feet', 'hands', 'rest']\n"
     ]
    }
   ],
   "source": [
    "# WARNING: If you plan to use this script, know that the Lee2019MI database is quite extensive. \n",
    "# Therefore, I recommend loading half of the database at a time (e.g. m_dataset.get_data([m_dataset.subject_list[1,2,3,4,...]])).\n",
    "# Load Database \n",
    "m_dataset = datasets.PhysionetMI()\n",
    "m_data = m_dataset.get_data(subjects = [m_dataset.subject_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canal list : ['FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FT8', 'T7', 'T8', 'T9', 'T10', 'TP7', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz', 'STIM']\n"
     ]
    }
   ],
   "source": [
    "#See all canal names (EEG, misc, stim...)\n",
    "raw = m_data[1]['0']['0']\n",
    "print(\"Canal list :\", raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canal index STIM is : 64\n"
     ]
    }
   ],
   "source": [
    "# Know what index is stim channel\n",
    "stm_name = 'STIM'\n",
    "stim_idx = raw.ch_names.index(stm_name)\n",
    "print(f\"Canal index {stm_name} is : {stim_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20000)\n",
      "Value : 0.0, Occurences count : 19970\n",
      "Value : 1.0, Occurences count : 15\n",
      "Value : 2.0, Occurences count : 8\n",
      "Value : 3.0, Occurences count : 7\n"
     ]
    }
   ],
   "source": [
    "#count stim data unique values (depends on the database)\n",
    "stim_data = raw.get_data(picks=stim_idx)\n",
    "print(stim_data.shape)\n",
    "unique_vals, counts = np.unique(stim_data, return_counts=True)\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurences count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysionetMI Task 2 runs\n",
    "run_keys = ['0', '1', '2']\n",
    "\n",
    "# Initialize a list to store the data from each run\n",
    "all_runs_data = []\n",
    "\n",
    "# Iterate over each training run and extract its data\n",
    "for run in run_keys:\n",
    "    raw_run = m_data[1]['0'][run]\n",
    "    # Extract the data: shape (n_channels, n_times_run)\n",
    "    run_data = raw_run.get_data()\n",
    "    all_runs_data.append(run_data)\n",
    "\n",
    "# Concatenate the data along the time axis (axis=1)\n",
    "concatenated_data = np.concatenate(all_runs_data, axis=1)  # forme: (n_channels, total_timesamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de dataT : (60000, 65)\n",
      "Forme de dataT : (59759, 65)\n"
     ]
    }
   ],
   "source": [
    "# Transpose to get dataT of shape (total_timesamples, n_channels)\n",
    "dataT = concatenated_data.T\n",
    "print(\"Shape of dataT before dropping rows:\", dataT.shape)\n",
    "\n",
    "# Remove all time samples (rows) if they only contain 0s\n",
    "# To be sure, we check if the sum per row is equal to 0\n",
    "nonzero_indices = np.where(np.sum(dataT, axis=1) != 0)[0]\n",
    "dataT = dataT[nonzero_indices, :]\n",
    "print(\"Shape of dataT before dropping rows:\", dataT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "n_times, n_channels = dataT.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df.iloc[:, 0] = df.iloc[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swapper les valeurs 1 et 2 dans la colonne stim\n",
    "stim_col = str(n_channels - 1)  # La dernière colonne contient les stimulations\n",
    "df[stim_col] = df[stim_col].replace({1: 4, 2: 1, 3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for subject in subject_list:\n",
    "    session_keys = sorted(m_data[subject].keys())\n",
    "    for idx, session in enumerate(session_keys, start=1):\n",
    "        # Récupérer la liste des runs dans cette session\n",
    "        run_keys = ['0', '1', '2']\n",
    "        # Initialiser une liste pour stocker les données de chaque run\n",
    "        all_runs_data = []\n",
    "        for run in run_keys:\n",
    "            raw_run = m_data[subject][session][run]\n",
    "            run_data = raw_run.get_data()  # forme: (n_channels, n_times_run)\n",
    "            all_runs_data.append(run_data)\n",
    "        \n",
    "        # Concaténer les données le long de l'axe temporel (axis=1)\n",
    "        concatenated_data = np.concatenate(all_runs_data, axis=1)  # (n_channels, total_timesamples)\n",
    "        \n",
    "        # Transposer pour obtenir dataT de forme (total_timesamples, n_channels)\n",
    "        dataT = concatenated_data.T\n",
    "        nonzero_indices = np.where(np.sum(dataT, axis=1) != 0)[0]\n",
    "        dataT = dataT[nonzero_indices, :]\n",
    "        print(\"Forme de dataT :\", dataT.shape)\n",
    "        n_times, n_channels = dataT.shape\n",
    "\n",
    "        # Création de la colonne de timestamps\n",
    "        timestamps = np.arange(n_times, dtype=int)\n",
    "        datacsv = np.column_stack((timestamps, dataT))\n",
    "        header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "        df = pd.DataFrame(datacsv, columns=header)\n",
    "        df[\"\"] = df[\"\"].astype(int)\n",
    "\n",
    "        # Swapper les valeurs 1 et 2 dans la colonne stim\n",
    "        stim_col = str(n_channels - 1)  # La dernière colonne contient les stimulations\n",
    "        df[stim_col] = df[stim_col].replace({1: 4, 2: 1, 3:2})\n",
    "\n",
    "        # Nommer le fichier\n",
    "        subject_str = f\"{int(subject):03d}\"\n",
    "        session_str = f\"{idx:02d}\"\n",
    "        filename = f\"subject_{subject_str}_session_{session_str}.csv\"\n",
    "        output_dir = 'C:/Users/doumif/work/Prog/PhysionetMI-T2'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "        # Affichage des informations avec les valeurs swappées\n",
    "        events = df[stim_col].values\n",
    "        n_lh = len(events[events == 1])  \n",
    "        n_rh = len(events[events == 2]) \n",
    "        rest = len(events[events == 4]) \n",
    "        print(f\"Nombre de Left hand (1): {n_lh}\")\n",
    "        print(f\"Nombre de Right hand (2): {n_rh}\")\n",
    "        print(f\"Nombre de Rest(4): {rest}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
