{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW (MOABB) to CSV\n",
    "\n",
    "This code convert the data sets from RAW format to CSV format using MOABB.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for PhysionetMI-T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from moabb import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Database \n",
    "m_dataset = datasets.PhysionetMI()\n",
    "m_data = m_dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all canal names (EEG, misc, stim...)\n",
    "raw = m_data[1]['0']['0']\n",
    "print(\"Canal list :\", raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Know what index is stim channel\n",
    "stm_name = 'STIM'\n",
    "stim_idx = raw.ch_names.index(stm_name)\n",
    "print(f\"Canal index {stm_name} is : {stim_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count stim data unique values (depends on the database)\n",
    "stim_data = raw.get_data(picks=stim_idx)\n",
    "print(stim_data.shape)\n",
    "unique_vals, counts = np.unique(stim_data, return_counts=True)\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurences count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysionetMI Task 2 runs\n",
    "run_keys = ['0', '1', '2']\n",
    "\n",
    "# Initialize a list to store the data from each run\n",
    "all_runs_data = []\n",
    "\n",
    "# Iterate over each training run and extract its data\n",
    "for run in run_keys:\n",
    "    raw_run = m_data[1]['0'][run]\n",
    "    # Extract the data: shape (n_channels, n_times_run)\n",
    "    run_data = raw_run.get_data()\n",
    "    all_runs_data.append(run_data)\n",
    "\n",
    "# Concatenate the data along the time axis (axis=1)\n",
    "concatenated_data = np.concatenate(all_runs_data, axis=1)  # forme: (n_channels, total_timesamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose to get dataT of shape (total_timesamples, n_channels)\n",
    "dataT = concatenated_data.T\n",
    "print(\"Shape of dataT before dropping rows:\", dataT.shape)\n",
    "\n",
    "# Remove all time samples (rows) if they only contain 0s\n",
    "# To be sure, we check if the sum per row is equal to 0\n",
    "nonzero_indices = np.where(np.sum(dataT, axis=1) != 0)[0]\n",
    "dataT = dataT[nonzero_indices, :]\n",
    "print(\"Shape of dataT before dropping rows:\", dataT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize labels in the stimulation channel (last column):\n",
    "# Change marker 1 to 4\n",
    "dataT[:, -1] = np.where(dataT[:, -1] == 1, 4, dataT[:, -1])\n",
    "# Change marker 2 to 1\n",
    "dataT[:, -1] = np.where(dataT[:, -1] == 2, 1, dataT[:, -1])\n",
    "# Change marker 3 to 2 \n",
    "dataT[:, -1] = np.where(dataT[:, -1] == 3, 2, dataT[:, -1])\n",
    "print(\"Shape of dataT:\", dataT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last column (stim channel)\n",
    "stim_col = dataT[:, -1]\n",
    "\n",
    "# Count the unique values\n",
    "unique_vals, counts = np.unique(stim_col, return_counts=True)\n",
    "\n",
    "# Loop through unique values and their counts to print the results\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurrence count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "n_times, n_channels = dataT.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df.iloc[:, 0] = df.iloc[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for all subjects\n",
    "subject_list = list(m_data.keys())\n",
    "\n",
    "for subject in subject_list:\n",
    "    # Get the list of runs in this session\n",
    "    run_keys = ['0', '1', '2']\n",
    "    # Initialize a list to store the data from each run\n",
    "    all_runs_data = []\n",
    "    for run in run_keys:\n",
    "        raw_run = m_data[subject]['0'][run]\n",
    "        run_data = raw_run.get_data()  # shape: (n_channels, n_times_run)\n",
    "        all_runs_data.append(run_data)\n",
    "    \n",
    "    # Concatenate the data along the time axis (axis=1)\n",
    "    concatenated_data = np.concatenate(all_runs_data, axis=1)  # (n_channels, total_timesamples)\n",
    "    \n",
    "    # Transpose to get dataT of shape (total_timesamples, n_channels)\n",
    "    dataT = concatenated_data.T\n",
    "    # Filter out time samples (rows) where the sum across all channels is zero\n",
    "    nonzero_indices = np.where(np.sum(dataT, axis=1) != 0)[0]\n",
    "    dataT = dataT[nonzero_indices, :]\n",
    "    print(\"Shape of dataT:\", dataT.shape)\n",
    "    n_times, n_channels = dataT.shape\n",
    "\n",
    "    # Standardize labels in the stimulation channel (last column):\n",
    "    # Change marker 1 to 4 (Rest)\n",
    "    dataT[:, -1] = np.where(dataT[:, -1] == 1, 4, dataT[:, -1])\n",
    "    # Change marker 2 to 1 (Left Hand)\n",
    "    dataT[:, -1] = np.where(dataT[:, -1] == 2, 1, dataT[:, -1])\n",
    "    # Change marker 3 to 2 (Right Hand)\n",
    "    dataT[:, -1] = np.where(dataT[:, -1] == 3, 2, dataT[:, -1])\n",
    "\n",
    "    # Create the timestamps column\n",
    "    timestamps = np.arange(n_times, dtype=int)\n",
    "    datacsv = np.column_stack((timestamps, dataT))\n",
    "    header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "    df = pd.DataFrame(datacsv, columns=header)\n",
    "    df[\"\"] = df[\"\"].astype(int)\n",
    "\n",
    "    # Name the file\n",
    "    subject_str = f\"{int(subject):03d}\"\n",
    "    filename = f\"subject_{subject_str}_session_01.csv\"\n",
    "    # Export the DataFrame to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    # Display information with swapped values\n",
    "    events = df.iloc[:, -1] # Using iloc to target the last column\n",
    "    n_lh = len(events[events == 1])  \n",
    "    n_rh = len(events[events == 2]) \n",
    "    rest = len(events[events == 4]) \n",
    "    print(f\"Number of Left hand (1): {n_lh}\")\n",
    "    print(f\"Number of Right hand (2): {n_rh}\")\n",
    "    print(f\"Number of Rest (4): {rest}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
