{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW (MOABB) to CSV\n",
    "\n",
    "This code convert the data sets from RAW format to CSV format using MOABB.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for Zhou2016 (new version as of the last update from MOABB (Jul 28, 2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from moabb import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Database\n",
    "m_dataset = datasets.Zhou2016()\n",
    "m_data = m_dataset.get_data(subjects=[m_dataset.subject_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all canal names (EEG, misc, stim...)\n",
    "raw = m_data[1]['0']['0']\n",
    "print(\"Canal list :\", raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get events from annonations\n",
    "events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "# create stim canal\n",
    "stim_data = np.zeros((1, len(raw.times)))\n",
    "\n",
    "# for each event, place the value of the event in stim canal\n",
    "for event in events_from_annot:\n",
    "    stim_data[0, event[0]] = event[2]\n",
    "\n",
    "# Add stim canal in raw object\n",
    "info = mne.create_info(['STIM'], raw.info['sfreq'], ['stim'])\n",
    "stim_raw = mne.io.RawArray(stim_data, info)\n",
    "raw.add_channels([stim_raw], force_update_info = True)\n",
    "\n",
    "print(\"Canal list :\", raw.ch_names)\n",
    "print(raw.ch_names[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Know what index is stim channel\n",
    "stim_name = 'STIM'\n",
    "stim_idx = raw.ch_names.index(stim_name)\n",
    "print(f\"Canal index {stim_name} is : {stim_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count stim data unique values (1 non target, 2 = target with a ratio needed of 5 to 1)\n",
    "stim_data = raw.get_data(picks=stim_idx)\n",
    "print(stim_data.shape)\n",
    "unique_vals, counts = np.unique(stim_data, return_counts=True)\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurences count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, for subject 1 and a given session '0'\n",
    "subject = 1\n",
    "session = '0'\n",
    "\n",
    "# Retrieve the list of runs in this session\n",
    "run_keys = sorted(m_data[subject][session].keys())\n",
    "print(\"Runs found in the session:\", run_keys)\n",
    "\n",
    "# Initialize a list to store the data from each run\n",
    "all_runs_data = []\n",
    "\n",
    "# Iterate through each run and extract its data\n",
    "for run in run_keys:\n",
    "    raw_run = m_data[subject][session][run]\n",
    "    # get events from annonations\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(raw_run)\n",
    "\n",
    "    # create stim canal\n",
    "    stim_data = np.zeros((1, len(raw_run.times)))\n",
    "\n",
    "    # for each event, place the value of the event in stim canal\n",
    "    for event in events_from_annot:\n",
    "        stim_data[0, event[0]] = event[2]\n",
    "\n",
    "    # Add stim canal in raw object\n",
    "    info = mne.create_info(['STIM'], raw_run.info['sfreq'], ['stim'])\n",
    "    stim_raw = mne.io.RawArray(stim_data, info)\n",
    "    raw_run.add_channels([stim_raw], force_update_info = True)\n",
    "\n",
    "    print(\"Canal list :\", raw_run.ch_names)\n",
    "    print(raw_run.ch_names[-1]) \n",
    "    run_data = raw_run.get_data()  # shape: (n_channels, n_times_run)\n",
    "    all_runs_data.append(run_data)\n",
    "\n",
    "# Concatenate the data along the time axis (axis=1)\n",
    "concatenated_data = np.concatenate(all_runs_data, axis=1)  # shape: (n_channels, total_timesamples)\n",
    "\n",
    "# Transpose to get an array of shape (total_timesamples, n_channels)\n",
    "dataT = concatenated_data.T\n",
    "print(\"Shape of dataT:\", dataT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last column (stim channel)\n",
    "stim_col = dataT[:, -1]\n",
    "\n",
    "# Count the unique values\n",
    "unique_vals, counts = np.unique(stim_col, return_counts=True)\n",
    "\n",
    "# Loop through unique values and their counts to print the results\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurrence count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "n_times, n_channels = dataT.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df[\"\"] = df[\"\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for all subjects\n",
    "subject_list = list(m_data.keys())\n",
    "\n",
    "for subject in subject_list:\n",
    "    session_keys = sorted(m_data[subject].keys())\n",
    "    for session in session_keys:\n",
    "        # Retrieve the list of runs in this session\n",
    "        run_keys = sorted(m_data[subject][session].keys())\n",
    "        \n",
    "        # Initialize a list to store data for each run\n",
    "        all_runs_data = []\n",
    "        for run in run_keys:\n",
    "            raw_run = m_data[subject][session][run]\n",
    "            # Get events from annotations\n",
    "            events_from_annot, event_dict = mne.events_from_annotations(raw_run)\n",
    "\n",
    "            # Create stimulation channel\n",
    "            stim_data = np.zeros((1, len(raw_run.times)))\n",
    "\n",
    "            # For each event, place the event value into the stim channel\n",
    "            for event in events_from_annot:\n",
    "                stim_data[0, event[0]] = event[2]\n",
    "\n",
    "            # Add stim channel to the raw object\n",
    "            info = mne.create_info(['STIM'], raw_run.info['sfreq'], ['stim'])\n",
    "            stim_raw = mne.io.RawArray(stim_data, info)\n",
    "            raw_run.add_channels([stim_raw], force_update_info=True)\n",
    "\n",
    "            print(\"Channel list:\", raw_run.ch_names)\n",
    "            print(\"Last channel:\", raw_run.ch_names[-1]) \n",
    "            run_data = raw_run.get_data()  # shape: (n_channels, n_times_run)\n",
    "            all_runs_data.append(run_data)\n",
    "        \n",
    "        # Concatenate data along the time axis (axis=1)\n",
    "        concatenated_data = np.concatenate(all_runs_data, axis=1)  # (n_channels, total_timesamples)\n",
    "        \n",
    "        # Transpose to get dataT with shape (total_timesamples, n_channels)\n",
    "        dataT = concatenated_data.T\n",
    "        n_times, n_channels = dataT.shape\n",
    "        \n",
    "        # Create the timestamps column\n",
    "        timestamps = np.arange(n_times, dtype=int)\n",
    "        datacsv = np.column_stack((timestamps, dataT))\n",
    "        header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "        df = pd.DataFrame(datacsv, columns=header)\n",
    "        df[\"\"] = df[\"\"].astype(int)\n",
    "        \n",
    "        # File naming\n",
    "        subject_str = f\"{int(subject):02d}\"\n",
    "        # get the right session number from the string (e.g., '0train' or '1test')\n",
    "        session_str = f\"{int(session[0]) + 1:02d}\"\n",
    "        filename = f\"subject_{subject_str}_session_{session_str}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Saved file: {filename}\")\n",
    "\n",
    "        # Display info\n",
    "        events = df.iloc[:, -1]\n",
    "        n_lh = len(events[events == 1])  \n",
    "        n_rh = len(events[events == 2]) \n",
    "        n_f = len(events[events == 3]) \n",
    "        print(f\"Number of Left hand (1): {n_lh}\")\n",
    "        print(f\"Number of Right hand (2): {n_rh}\")\n",
    "        print(f\"Number of feet (3): {n_f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
