{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726fca87",
   "metadata": {},
   "source": [
    "RAW (Base repo) to CSV\n",
    "\n",
    "This code convert the data sets from RAW format to CSV format using MOABB.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for bi2012-T\n",
    "\n",
    "---\n",
    "\n",
    "**Important Note: bi2012**\n",
    "\n",
    "The original files were reorganized to simplify the processing:\n",
    "\n",
    "* **Structure**: Files were moved from nested folders (`subject_XX/subject_XX/`) directly into `CSV_bi2012/subject_XX/`.\n",
    "* **Content**: Each folder now contains the **online** and **training** CSV files.\n",
    "* **Cleanup**: I deleted the `__MACOSX` folders and empty subdirectories to keep the directory clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecb4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4037b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for 1 file\n",
    "temp_file = 'D:\\\\Travail\\\\backupPCgipsa\\\\taf\\\\officework\\\\gipsa bases\\\\CSV bi2012\\\\subject_01\\\\training.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ec4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process the data\n",
    "data = pd.read_csv(temp_file, header=None)\n",
    "data = np.array(data)\n",
    "mask_valid_rows = ~np.isnan(data).any(axis=1)\n",
    "data = data[mask_valid_rows]\n",
    "\n",
    "# rearranging the stim column\n",
    "data[:, 19] = data[:, 19] * 2\n",
    "\n",
    "# Transfer 2s from target column (column 19) to non_target column (column 18)\n",
    "mask = data[:, 19] == 2\n",
    "data[mask, 18] = 2\n",
    "data = np.delete(data, [19], axis=1)\n",
    "\n",
    "# convert to µvolt\n",
    "data[:, 1:-1] = data[:, 1:-1] * 1e-6\n",
    "\n",
    "# delete original timestamp col\n",
    "data = np.delete(data, [0], axis=1)\n",
    "\n",
    "# delete Fz ground electrode col\n",
    "data = np.delete(data, [2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac761c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last column (stim channel)\n",
    "stim_col = data[:, -1]\n",
    "\n",
    "# Count the unique values\n",
    "unique_vals, counts = np.unique(stim_col, return_counts=True)\n",
    "\n",
    "# Loop through unique values and their counts to print the results\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurrence count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc646fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "n_times, n_channels = data.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, data))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df[\"\"] = df[\"\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ffc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all subjects\n",
    "# Path to the directory containing all .csv files of the dataset\n",
    "file_dir = \"D:\\\\Travail\\\\backupPCgipsa\\\\taf\\\\officework\\\\gipsa bases\\\\CSV bi2012\"\n",
    "subject_list = [os.path.join(file_dir, file) for file in os.listdir(file_dir) if os.path.isdir(os.path.join(file_dir, file))]\n",
    "\n",
    "for subject in subject_list:\n",
    "\n",
    "    # Extract subject number from the subject folder name\n",
    "    subject_folder = os.path.basename(subject)\n",
    "    subject_num = subject_folder.split('_')[1]  # Extract 'XX' from 'subject_XX'\n",
    "\n",
    "    # Construct path to the session 1 CSV file within the subject folder\n",
    "    csv_file_path = os.path.join(subject, \"training.csv\")\n",
    "\n",
    "    # Read and process the data\n",
    "    data = pd.read_csv(csv_file_path, header=None)\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Remove rows containing NaN values\n",
    "    mask_valid_rows = ~np.isnan(data).any(axis=1)\n",
    "    data = data[mask_valid_rows]\n",
    "\n",
    "    # Rearranging the stimulation column\n",
    "    # Multiply target labels by 2 (e.g., changing 1 to 2)\n",
    "    data[:, 19] = data[:, 19] * 2\n",
    "\n",
    "    # Transfer target markers (2s) from target column (19) to non-target column (18)\n",
    "    mask = data[:, 19] == 2\n",
    "    data[mask, 18] = 2\n",
    "    \n",
    "    # Delete the redundant target column (index 19)\n",
    "    data = np.delete(data, [19], axis=1)\n",
    "\n",
    "    # Convert values to microvolts (µV)\n",
    "    data[:, 1:-1] = data[:, 1:-1] * 1e-6\n",
    "\n",
    "    # Delete the original timestamp column (index 0)\n",
    "    data = np.delete(data, [0], axis=1)\n",
    "\n",
    "    # delete Fz ground electrode col\n",
    "    data = np.delete(data, [2], axis=1)\n",
    "\n",
    "    # Generate new timestamps and header\n",
    "    n_times, n_channels = data.shape\n",
    "    timestamps = np.arange(n_times, dtype=int)\n",
    "    data_with_timestamp = np.column_stack((timestamps, data))\n",
    "    header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "    # Convert the array to a DataFrame and ensure integer timestamps\n",
    "    df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "    df[\"\"] = df[\"\"].astype(int)\n",
    "\n",
    "    # Construct the final filename\n",
    "    filename = f\"subject_{subject_num}_session_01.csv\"\n",
    "\n",
    "    # Export the processed DataFrame to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved file: {filename}\")\n",
    "\n",
    "    # Display information\n",
    "    events = df.iloc[:, -1]\n",
    "    n_nt = len(events[events == 1]) \n",
    "    n_t = len(events[events == 2]) \n",
    "    print(f\"Number of Non-Target (1): {n_nt}\")\n",
    "    print(f\"Number of Target (2): {n_t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
