{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726fca87",
   "metadata": {},
   "source": [
    "RAW (Base repo) to CSV\n",
    "\n",
    "This code convert the data sets from RAW format to CSV format using MOABB.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for bi2013a-NAO \n",
    "\n",
    "Important Note:\n",
    "\n",
    "The original bi2013a files from the base repository are organized into one folder per subject_session. Each folder contains 4 .mat files and 4 .csv files, numbered from 1 to 4 (e.g., 1.csv, 2.csv, etc.).\n",
    "\n",
    "To standardize the processing, a specific function has been designed to rearrange and separate this database into four distinct databases based on the file numbering:\n",
    "\n",
    "- bi2013-AT: Corresponds to 1.csv (Adaptative - Training).\n",
    "\n",
    "- bi2013-AO: Corresponds to 2.csv (Adaptative - Online).\n",
    "\n",
    "- bi2013-NAT: Corresponds to 3.csv (Non-Adaptative - Training).\n",
    "\n",
    "- bi2013-NAO: Corresponds to 4.csv (Non-Adaptative - Online).\n",
    "\n",
    "Once separated, the data processing pipeline remains identical to the other databases in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Import decimate \n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from ConvTools import decimate, rearrange, df_to_mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21dfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange bi2013a-NAO\n",
    "source = \"D:\\\\Travail\\\\backupPCgipsa\\\\taf\\\\officework\\\\gipsa bases\\\\CSV zenodo bi2013a\\\\\"\n",
    "file_dir = \"D:\\\\Travail\\\\backupPCgipsa\\\\taf\\\\officework\\\\gipsa bases\\\\CSV bi2013a-NAO\\\\\"\n",
    "csv_num = 4\n",
    "rearrange(csv_num, source, file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ed07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for 1 file\n",
    "temp_file = \"D:\\\\Travail\\\\backupPCgipsa\\\\taf\\\\officework\\\\gipsa bases\\\\CSV bi2013a-NAO\\\\subject_01_session_01.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c16108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv(temp_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345a4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "sfreq = 512\n",
    "decimation_factor = 2\n",
    "stim_name = 'STI'\n",
    "\n",
    "raw = df_to_mne(df, sfreq)\n",
    "raw_decimated = decimate(raw, sfreq, decimation_factor, stim_name)\n",
    "data = raw_decimated.get_data()\n",
    "\n",
    "# Transpose\n",
    "dataT = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a890bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label standardization\n",
    "# Convert 33285 to 2 and 33286 to 1 in stim column\n",
    "dataT[:, -1] = np.where(dataT[:, -1] == 33285, 2, dataT[:, -1])\n",
    "dataT[:, -1] = np.where(dataT[:, -1] == 33286, 1, dataT[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f474f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last column (stim channel)\n",
    "stim_col = dataT[:, -1]\n",
    "\n",
    "# Count the unique values\n",
    "unique_vals, counts = np.unique(stim_col, return_counts=True)\n",
    "\n",
    "# Loop through unique values and their counts to print the results\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurrence count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62e7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "n_times, n_channels = dataT.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df[\"\"] = df[\"\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e576d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all subject folders/files in the directory\n",
    "subject_list = [os.path.join(file_dir, file) for file in os.listdir(file_dir)]\n",
    "\n",
    "for subject in subject_list:\n",
    "    # Read the data\n",
    "    df = pd.read_csv(subject, header=0)\n",
    "\n",
    "    # Signal Processing Parameters\n",
    "    sfreq = 512\n",
    "    decimation_factor = 2\n",
    "    stim_name = 'STI'\n",
    "\n",
    "    # Convert DataFrame to MNE Raw object and apply decimation (filtering + resampling)\n",
    "    raw = df_to_mne(df, sfreq)\n",
    "    raw_decimated = decimate(raw, sfreq, decimation_factor, stim_name)\n",
    "    data = raw_decimated.get_data()\n",
    "\n",
    "    # Transpose data to (time_samples, channels) format\n",
    "    dataT = data.T\n",
    "    \n",
    "    # Label standardization for the stimulation channel (last column)\n",
    "    # Map raw hardware markers to target (2) and non-target (1) labels\n",
    "    dataT[:, -1] = np.where(dataT[:, -1] == 33285, 2, dataT[:, -1])\n",
    "    dataT[:, -1] = np.where(dataT[:, -1] == 33286, 1, dataT[:, -1])\n",
    "\n",
    "    # Generate integer timestamps and prepare the CSV header\n",
    "    n_times, n_channels = dataT.shape\n",
    "    timestamps = np.arange(n_times, dtype=int)\n",
    "    data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "    header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "    # Format as DataFrame and ensure the timestamp column is integer type\n",
    "    df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "    df[\"\"] = df[\"\"].astype(int)\n",
    "\n",
    "    # Extract the filename from the path\n",
    "    filename = os.path.basename(subject)\n",
    "\n",
    "    # Export the processed DataFrame to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved file: {filename}\")\n",
    "\n",
    "    # Display information\n",
    "    events = df.iloc[:, -1]\n",
    "    n_nt = len(events[events == 1]) \n",
    "    n_t = len(events[events == 2]) \n",
    "    print(f\"Number of Non-Target (1): {n_nt}\")\n",
    "    print(f\"Number of Target (2): {n_t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
