{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOABB to CSV / RAW to CSV\n",
    "\n",
    "This code convert the data sets in RAW format to CSV format.\n",
    "\n",
    "It has been specifically conceived for BCI data.\n",
    "\n",
    "This script is for GrossWentrup2009\n",
    "\n",
    "Original data from GrossWentrup2009 was downsampled to 250Hz to reduce csv size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import moabb.datasets\n",
    "import mne\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimate(raw, sfreq, decimation_factor):\n",
    "    \n",
    "    \"\"\"\n",
    "    Decimate Raw data and display informations for validation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_path : str\n",
    "        EEG data\n",
    "    sfreq : int \n",
    "        Base sampling rate or frequency (Hz)\n",
    "    decimation_factor : int\n",
    "        Decimation factor, must be an integer and the result\n",
    "        of the new frequency needs to be an integer too\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    raw_decimated : mne.io.RawArray\n",
    "        Decimated data\n",
    "    \"\"\"\n",
    "    # 1. Loading of raw data\n",
    "\n",
    "    print(f\"Original sampling frequency : {raw.info['sfreq']} Hz\")\n",
    "    new_freq = sfreq/decimation_factor\n",
    "    print(f\"New sampling frequency will be : {new_freq} Hz\")\n",
    "\n",
    "    \n",
    "    h_freq = int((new_freq/3)-2) # h_freq needs to be lower than 1/3 of new_freq\n",
    "\n",
    "    # 2. Low-pass Filter\n",
    "    print(\"\\n=== Application du filtre passe-bas ===\")\n",
    "    raw_filtered = raw.copy().filter(\n",
    "        l_freq=None,\n",
    "        h_freq=h_freq,      \n",
    "        method='iir',\n",
    "        iir_params=dict(\n",
    "            order=4,\n",
    "            ftype='butter'\n",
    "        ),\n",
    "        phase='zero'    # forward-backward filtering \n",
    "    )\n",
    "\n",
    "    # 3. Decimation\n",
    "    print(\"\\n=== Data decimation===\")\n",
    "    raw_decimated = raw_filtered.copy().resample(new_freq)\n",
    "\n",
    "    print(\"\\n=== EVENTS ===\")\n",
    "    events_orig = mne.find_events(raw, stim_channel='STIM')\n",
    "    events_dec = mne.find_events(raw_decimated, stim_channel='STIM')\n",
    "    \n",
    "    print(\"\\n=== Labels Check ===\")\n",
    "    stim_data = raw.get_data(picks='stim')\n",
    "    stim_data_d = raw_decimated.get_data(picks='stim')\n",
    "    unique_vals, counts = np.unique(stim_data[stim_data != 0], return_counts=True)\n",
    "    unique_valsd, countsd = np.unique(stim_data_d[stim_data_d != 0], return_counts=True)\n",
    "    print(\"Original:\")\n",
    "    for val, count in zip(unique_vals, counts):\n",
    "        print(f\"Value : {val}, Occurences count : {count}\")\n",
    "    print(\"Decimated:\")\n",
    "    for val, count in zip(unique_valsd, countsd):\n",
    "        print(f\"Value : {val}, Occurences count : {count}\")\n",
    "\n",
    "    # Validation\n",
    "    print(\"\\n=== Checking discrepancies between events ===\")\n",
    "\n",
    "    # Calculation of deviations for original data\n",
    "    gaps_orig = np.diff(events_orig[:, 0]) / raw.info['sfreq']  # in seconds\n",
    "\n",
    "    # Calculation of deviations for decimated data\n",
    "    gaps_dec = np.diff(events_dec[:, 0]) / raw_decimated.info['sfreq']  # in seconds\n",
    "\n",
    "    # Displaying deviation statistics\n",
    "    print(\"\\nTime between events (seconds):\")\n",
    "    print(\"Original:\")\n",
    "    print(f\"  Min: {np.min(gaps_orig):.3f}s\")\n",
    "    print(f\"  Max: {np.max(gaps_orig):.3f}s\")\n",
    "    print(f\"  Mean: {np.mean(gaps_orig):.3f}s\")\n",
    "    print(f\"  Standard deviation: {np.std(gaps_orig):.3f}s\")\n",
    "\n",
    "\n",
    "    print(\"\\nDecimated:\")\n",
    "    print(f\"  Min: {np.min(gaps_dec):.3f}s\")\n",
    "    print(f\"  Max: {np.max(gaps_dec):.3f}s\")\n",
    "    print(f\"  Mean: {np.mean(gaps_dec):.3f}s\")\n",
    "    print(f\"  Standard deviation: {np.std(gaps_dec):.3f}s\")\n",
    "\n",
    "    # Display of the first 5 deviations for comparison\n",
    "    print(\"\\nComparison of the first 5 gaps:\")\n",
    "    print(\"N° | Original (s) | Decimated (s) | Diff (ms)\")\n",
    "    print(\"-\" * 45)\n",
    "    for i in range(min(5, len(gaps_orig))):\n",
    "        diff_ms = (gaps_orig[i] - gaps_dec[i]) * 1000\n",
    "        print(f\"{i+1:2d} | {gaps_orig[i]:11.3f} | {gaps_dec[i]:10.3f} | {diff_ms:14.3f}\")\n",
    "\n",
    "    return raw_decimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dataset = moabb.datasets.GrosseWentrup2009()\n",
    "m_data = m_dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all canal names (EEG, misc, stim...)\n",
    "raw = m_data[1]['0']['0']\n",
    "raw\n",
    "print(\"Canal list :\", raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Know what index is stim channel (we will need it later for the CSV to NY conversion)\n",
    "stim_channel_name = 'STIM'\n",
    "stim_idx = raw.ch_names.index(stim_channel_name)\n",
    "print(f\"Canal index {stim_channel_name} is : {stim_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count stim data unique values (1 non target, 2 = target with a ratio needed of 5 to 1)\n",
    "stim_data = raw.get_data(picks=stim_idx)\n",
    "print(stim_data.shape)\n",
    "unique_vals, counts = np.unique(stim_data, return_counts=True)\n",
    "\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Value : {val}, Occurences count : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 500\n",
    "decimation_factor = 2 \n",
    "raw_decimated = decimate(raw, sfreq, decimation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose to invert columns/lines\n",
    "data = raw_decimated.get_data()\n",
    "dataT = data.T\n",
    "print(dataT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating timestamps and header\n",
    "n_times, n_channels = dataT.shape\n",
    "timestamps = np.arange(n_times, dtype=int)\n",
    "data_with_timestamp = np.column_stack((timestamps, dataT))\n",
    "header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "\n",
    "# Removing decimals from timestamps\n",
    "df = pd.DataFrame(data_with_timestamp, columns=header)\n",
    "df.iloc[:, 0] = df.iloc[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check csv file\n",
    "output_dir = 'C:/Users/doumif/work/Prog/Grosswentrup2019'\n",
    "filename = \"data.csv\"\n",
    "filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = m_dataset.subject_list\n",
    "sfreq = 500\n",
    "decimation_factor = 2 \n",
    "\n",
    "for subject in subject_list:\n",
    "    session_keys = sorted(m_data[subject].keys())\n",
    "    for idx, session in enumerate(session_keys, start=1):\n",
    "        raw_session = m_data[subject]['0']['0']\n",
    "        raw_decimated = decimate(raw_session, sfreq, decimation_factor)\n",
    "        data = raw_decimated.get_data()\n",
    "\n",
    "        # Transposer pour obtenir dataT de forme (total_timesamples, n_channels)\n",
    "        dataT = data.T\n",
    "        n_times, n_channels = dataT.shape\n",
    "\n",
    "        # Création de la colonne de timestamps\n",
    "        timestamps = np.arange(n_times, dtype=int)\n",
    "        datacsv = np.column_stack((timestamps, dataT))\n",
    "        header = [\"\"] + [str(i) for i in range(n_channels)]\n",
    "        df = pd.DataFrame(datacsv, columns=header)\n",
    "        df[\"\"] = df[\"\"].astype(int)\n",
    "\n",
    "        stim_col = str(n_channels - 1)  # La dernière colonne contient les stimulations\n",
    "        subject_str = f\"{int(subject):02d}\"\n",
    "        session_str = f\"{idx:02d}\"\n",
    "        filename = f\"subject_{subject_str}_session_{session_str}.csv\"\n",
    "        output_dir = 'C:/Users/doumif/work/Prog/GrosseWentrup2009'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "        # Affichage des informations\n",
    "        events = df[stim_col].values\n",
    "        n_rh = len(events[events == 2])\n",
    "        n_lh = len(events[events == 1])\n",
    "        print(f\"\\nFichier sauvegardé : {filename}\")\n",
    "        print(f\"Nombre de Left hand (1): {n_lh}\")        \n",
    "        print(f\"Nombre de Right hand (2): {n_rh}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
